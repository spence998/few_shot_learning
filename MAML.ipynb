{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c6c2ae8-5e00-4f64-a9a0-51a97c123dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import autograd\n",
    "from torch.utils import tensorboard\n",
    "\n",
    "import imageio\n",
    "from torch.utils.data import dataset, sampler, dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "114bbb85-2aaa-49d1-9d24-7c6d624a7b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_INPUT_CHANNELS = 1\n",
    "NUM_HIDDEN_CHANNELS = 32\n",
    "KERNEL_SIZE = 3\n",
    "NUM_CONV_LAYERS = 4\n",
    "SUMMARY_INTERVAL = 10\n",
    "SAVE_INTERVAL = 100\n",
    "LOG_INTERVAL = 10\n",
    "VAL_INTERVAL = LOG_INTERVAL * 5\n",
    "NUM_TEST_TASKS = 600\n",
    "\n",
    "NUM_TRAIN_CLASSES = 1100\n",
    "NUM_VAL_CLASSES = 100\n",
    "NUM_TEST_CLASSES = 423\n",
    "NUM_SAMPLES_PER_CLASS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4c98b02-ece4-433c-a941-9e5f02dd958f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(file_path):\n",
    "    \"\"\"Loads and transforms an Omniglot image\"\"\"\n",
    "    x = imageio.imread(file_path)\n",
    "    x = torch.tensor(x, dtype=torch.float32).reshape([1, 28, 28])\n",
    "    x = x / 255.0\n",
    "    return 1 - x\n",
    "\n",
    "\n",
    "class OmniglotDataset(dataset.Dataset):\n",
    "    \"\"\"Omniglot dataset for meta-learning.\n",
    "\n",
    "    Each element of the dataset is a task. A task is specified with a key,\n",
    "    which is a tuple of class indices (no particular order). The corresponding\n",
    "    value is the instantiated task, which consists of sampled (image, label)\n",
    "    pairs.\n",
    "    \"\"\"\n",
    "\n",
    "    _BASE_PATH = './omniglot_resized'\n",
    "\n",
    "    def __init__(self, num_support, num_query):\n",
    "        \"\"\"Inits OmniglotDataset\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # get all character folders\n",
    "        self._character_folders = glob.glob(\n",
    "            os.path.join(self._BASE_PATH, '*/*/'))\n",
    "        assert len(self._character_folders) == (\n",
    "            NUM_TRAIN_CLASSES + NUM_VAL_CLASSES + NUM_TEST_CLASSES\n",
    "        )\n",
    "\n",
    "        # shuffle characters\n",
    "        np.random.default_rng(0).shuffle(self._character_folders)\n",
    "\n",
    "        # check problem arguments\n",
    "        assert num_support + num_query <= NUM_SAMPLES_PER_CLASS\n",
    "        self._num_support = num_support\n",
    "        self._num_query = num_query\n",
    "\n",
    "    def __getitem__(self, class_idxs):\n",
    "        \"\"\"Constructs a task.\n",
    "\n",
    "        Data for each class is sampled uniformly at random without replacement.\n",
    "        \"\"\"\n",
    "        images_support, images_query = [], []\n",
    "        labels_support, labels_query = [], []\n",
    "\n",
    "        for label, class_idx in enumerate(class_idxs):\n",
    "            # get a class's examples and sample from them\n",
    "            all_file_paths = glob.glob(\n",
    "                os.path.join(self._character_folders[class_idx], '*.png')\n",
    "            )\n",
    "            sampled_file_paths = np.random.default_rng().choice(\n",
    "                all_file_paths,\n",
    "                size=self._num_support + self._num_query,\n",
    "                replace=False\n",
    "            )\n",
    "            images = [load_image(file_path) for file_path in sampled_file_paths]\n",
    "\n",
    "            # split sampled examples into support and query\n",
    "            images_support.extend(images[:self._num_support])\n",
    "            images_query.extend(images[self._num_support:])\n",
    "            labels_support.extend([label] * self._num_support)\n",
    "            labels_query.extend([label] * self._num_query)\n",
    "\n",
    "        # aggregate into tensors\n",
    "        images_support = torch.stack(images_support)  # shape (N*S, C, H, W)\n",
    "        labels_support = torch.tensor(labels_support)  # shape (N*S)\n",
    "        images_query = torch.stack(images_query)\n",
    "        labels_query = torch.tensor(labels_query)\n",
    "\n",
    "        return images_support, labels_support, images_query, labels_query\n",
    "\n",
    "\n",
    "class OmniglotSampler(sampler.Sampler):\n",
    "    \"\"\"Samples task specification keys for an OmniglotDataset.\"\"\"\n",
    "    def __init__(self, split_idxs, num_way, num_tasks):\n",
    "        \"\"\"Inits OmniglotSampler\"\"\"\n",
    "        super().__init__(None)\n",
    "        self._split_idxs = split_idxs\n",
    "        self._num_way = num_way\n",
    "        self._num_tasks = num_tasks\n",
    "\n",
    "    def __iter__(self):\n",
    "        return (\n",
    "            np.random.default_rng().choice(\n",
    "                self._split_idxs,\n",
    "                size=self._num_way,\n",
    "                replace=False\n",
    "            ) for _ in range(self._num_tasks)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._num_tasks\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "def get_omniglot_dataloader(\n",
    "        split,\n",
    "        batch_size,\n",
    "        num_way,\n",
    "        num_support,\n",
    "        num_query,\n",
    "        num_tasks_per_epoch,\n",
    "        num_workers=0,\n",
    "):\n",
    "    \"\"\"Returns a dataloader.DataLoader for Omniglot\"\"\"\n",
    "\n",
    "    if split == 'train':\n",
    "        split_idxs = range(NUM_TRAIN_CLASSES)\n",
    "    elif split == 'val':\n",
    "        split_idxs = range(\n",
    "            NUM_TRAIN_CLASSES,\n",
    "            NUM_TRAIN_CLASSES + NUM_VAL_CLASSES\n",
    "        )\n",
    "    elif split == 'test':\n",
    "        split_idxs = range(\n",
    "            NUM_TRAIN_CLASSES + NUM_VAL_CLASSES,\n",
    "            NUM_TRAIN_CLASSES + NUM_VAL_CLASSES + NUM_TEST_CLASSES\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    return dataloader.DataLoader(\n",
    "        dataset=OmniglotDataset(num_support, num_query),\n",
    "        batch_size=batch_size,\n",
    "        sampler=OmniglotSampler(split_idxs, num_way, num_tasks_per_epoch),\n",
    "        num_workers=0,\n",
    "        collate_fn=identity,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        drop_last=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bef96880-3ec7-4b21-a0e8-9c8329cfe024",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAML:\n",
    "    \"\"\"Trains and assesses a MAML.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, num_outputs, num_inner_steps, inner_lr, learn_inner_lrs, outer_lr,\n",
    "    ):\n",
    "        meta_parameters = {}\n",
    "\n",
    "        # construct feature extractor\n",
    "        in_channels = NUM_INPUT_CHANNELS\n",
    "        for i in range(NUM_CONV_LAYERS):\n",
    "            meta_parameters[f'conv{i}'] = nn.init.xavier_uniform_(\n",
    "                torch.empty(\n",
    "                    NUM_HIDDEN_CHANNELS,\n",
    "                    in_channels,\n",
    "                    KERNEL_SIZE,\n",
    "                    KERNEL_SIZE,\n",
    "                    requires_grad=True,\n",
    "                )\n",
    "            )\n",
    "            meta_parameters[f'b{i}'] = nn.init.zeros_(\n",
    "                torch.empty(\n",
    "                    NUM_HIDDEN_CHANNELS,\n",
    "                    requires_grad=True,\n",
    "                )\n",
    "            )\n",
    "            in_channels = NUM_HIDDEN_CHANNELS\n",
    "\n",
    "        # construct linear head layer\n",
    "        meta_parameters[f'w{NUM_CONV_LAYERS}'] = nn.init.xavier_uniform_(\n",
    "            torch.empty(\n",
    "                num_outputs,\n",
    "                NUM_HIDDEN_CHANNELS,\n",
    "                requires_grad=True,\n",
    "            )\n",
    "        )\n",
    "        meta_parameters[f'b{NUM_CONV_LAYERS}'] = nn.init.zeros_(\n",
    "            torch.empty(\n",
    "                num_outputs,\n",
    "                requires_grad=True,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self._meta_parameters = meta_parameters\n",
    "        self._num_inner_steps = num_inner_steps\n",
    "        self._inner_lrs = {\n",
    "            k: torch.tensor(inner_lr, requires_grad=learn_inner_lrs)\n",
    "            for k in self._meta_parameters.keys()\n",
    "        }\n",
    "        self._outer_lr = outer_lr\n",
    "\n",
    "        self._optimizer = torch.optim.Adam(\n",
    "            list(self._meta_parameters.values()) +\n",
    "            list(self._inner_lrs.values()),\n",
    "            lr=self._outer_lr\n",
    "        )\n",
    "\n",
    "        self._start_train_step = 0\n",
    "\n",
    "    def _forward(self, images, parameters):\n",
    "        \"\"\"Computes predicted classification logits\"\"\"\n",
    "        x = images\n",
    "        for i in range(NUM_CONV_LAYERS):\n",
    "            x = F.conv2d(\n",
    "                input=x,\n",
    "                weight=parameters[f'conv{i}'],\n",
    "                bias=parameters[f'b{i}'],\n",
    "                stride=1,\n",
    "                padding='same'\n",
    "            )\n",
    "            x = F.batch_norm(x, None, None, training=True)\n",
    "            x = F.relu(x)\n",
    "        x = torch.mean(x, dim=[2, 3])\n",
    "        return F.linear(\n",
    "            input=x,\n",
    "            weight=parameters[f'w{NUM_CONV_LAYERS}'],\n",
    "            bias=parameters[f'b{NUM_CONV_LAYERS}']\n",
    "        )\n",
    "\n",
    "    def _inner_loop(self, images, labels, train):\n",
    "        \"\"\"Computes the adapted network parameters via the MAML inner loop\"\"\"\n",
    "        accuracies = []\n",
    "        parameters = {\n",
    "            k: torch.clone(v)\n",
    "            for k, v in self._meta_parameters.items()\n",
    "        }\n",
    "        for i in range(self._num_inner_steps):\n",
    "            logit = self._forward(images, parameters)\n",
    "            loss = F.cross_entropy(logit, labels)\n",
    "            gradients = autograd.grad(\n",
    "                loss,\n",
    "                parameters.values(),\n",
    "                create_graph=train\n",
    "            )\n",
    "\n",
    "            for i, (k, v) in enumerate(parameters.items()):\n",
    "                parameters[k] = v - self._inner_lrs[k] * gradients[i]\n",
    "\n",
    "            accuracies.append(\n",
    "                score(logit, labels)\n",
    "            )\n",
    "\n",
    "        logit = self._forward(images, parameters)\n",
    "        accuracies.append(\n",
    "            score(logit, labels)\n",
    "        )\n",
    "        return parameters, accuracies\n",
    "\n",
    "    def _outer_step(self, task_batch, train):\n",
    "        \"\"\"Computes the MAML loss and metrics on a batch of tasks\"\"\"\n",
    "        outer_loss_batch = []\n",
    "        accuracies_support_batch = []\n",
    "        accuracy_query_batch = []\n",
    "        for task in task_batch:\n",
    "            images_support, labels_support, images_query, labels_query = task\n",
    "            params, support_acc = self._inner_loop(images_support, labels_support, train)\n",
    "\n",
    "            logit = self._forward(images_query, params)\n",
    "            loss = F.cross_entropy(logit, labels_query)\n",
    "\n",
    "            outer_loss_batch.append(loss)\n",
    "            accuracies_support_batch.append(support_acc)\n",
    "            accuracy_query_batch.append(\n",
    "                score(logit, labels_query)\n",
    "            )\n",
    "        outer_loss = torch.mean(torch.stack(outer_loss_batch))\n",
    "        accuracies_support = np.mean(\n",
    "            accuracies_support_batch,\n",
    "            axis=0\n",
    "        )\n",
    "        accuracy_query = np.mean(accuracy_query_batch)\n",
    "        return outer_loss, accuracies_support, accuracy_query\n",
    "\n",
    "    def train(self, dataloader_train, dataloader_val):\n",
    "        print(f'Starting training at iteration {self._start_train_step}.')        \n",
    "        for i_step, task_batch in enumerate(\n",
    "                dataloader_train,\n",
    "                start=self._start_train_step\n",
    "        ):\n",
    "            self._optimizer.zero_grad()\n",
    "            outer_loss, accuracies_support, accuracy_query = (\n",
    "                self._outer_step(task_batch, train=True)\n",
    "            )\n",
    "            outer_loss.backward()\n",
    "            self._optimizer.step()\n",
    "\n",
    "            if i_step % LOG_INTERVAL == 0:\n",
    "                print(\n",
    "                    f'Iteration {i_step}: '\n",
    "                    f'loss: {outer_loss.item():.3f}, '\n",
    "                    f'pre-adaptation support accuracy: {accuracies_support[0]:.3f}, '\n",
    "                    f'post-adaptation support accuracy: {accuracies_support[-1]:.3f}, '\n",
    "                    f'post-adaptation query accuracy: {accuracy_query:.3f}'\n",
    "                )\n",
    "\n",
    "            if i_step % VAL_INTERVAL == 0:\n",
    "                losses = []\n",
    "                acc_pre_adapt_support = []\n",
    "                acc_post_adapt_support = []\n",
    "                acc_post_adapt_query = []\n",
    "                for val_task_batch in dataloader_val:\n",
    "                    outer_loss, accuracies_support, accuracy_query = (\n",
    "                        self._outer_step(val_task_batch, train=False)\n",
    "                    )\n",
    "                    losses.append(outer_loss.item())\n",
    "                    acc_pre_adapt_support.append(accuracies_support[0])\n",
    "                    acc_post_adapt_support.append(accuracies_support[-1])\n",
    "                    acc_post_adapt_query.append(accuracy_query)\n",
    "                loss = np.mean(losses)\n",
    "                acc_pre_adapt_support = np.mean(acc_pre_adapt_support)\n",
    "                acc_post_adapt_support = np.mean(acc_post_adapt_support)\n",
    "                acc_post_adapt_query = np.mean(acc_post_adapt_query)\n",
    "                print(\n",
    "                    f'Validation: '\n",
    "                    f'loss: {loss:.3f}, '\n",
    "                    f'pre-adaptation support accuracy: '\n",
    "                    f'{acc_pre_adapt_support:.3f}, '\n",
    "                    f'post-adaptation support accuracy: '\n",
    "                    f'{acc_post_adapt_support:.3f}, '\n",
    "                    f'post-adaptation query accuracy: '\n",
    "                    f'{acc_post_adapt_query:.3f}'\n",
    "                )\n",
    "\n",
    "    def test(self, dataloader_test):\n",
    "        \"\"\"Evaluate the MAML on test tasks\"\"\"\n",
    "        accuracies = []\n",
    "        for task_batch in dataloader_test:\n",
    "            _, _, accuracy_query = self._outer_step(task_batch, train=False)\n",
    "            accuracies.append(accuracy_query)\n",
    "        mean = np.mean(accuracies)\n",
    "        std = np.std(accuracies)\n",
    "        mean_95_confidence_interval = 1.96 * std / np.sqrt(NUM_TEST_TASKS)\n",
    "        print(\n",
    "            f'Accuracy over {NUM_TEST_TASKS} test tasks: '\n",
    "            f'mean {mean:.3f}, '\n",
    "            f'95% confidence interval {mean_95_confidence_interval:.3f}'\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d912a09-9ad6-420e-ae41-38b9545bbaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(logits, labels):\n",
    "    \"\"\"Returns the mean accuracy of a model's predictions on a set of examples\"\"\"\n",
    "    y = torch.argmax(logits, dim=-1) == labels\n",
    "    y = y.type(torch.float)\n",
    "    return torch.mean(y).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3754d2-9d8a-420f-b31c-ddef48797334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    print(args)\n",
    "    maml = MAML(\n",
    "        args.num_way, args.num_inner_steps, args.inner_lr, args.learn_inner_lrs, args.outer_lr,\n",
    "    )\n",
    "    if not args.test:\n",
    "        num_training_tasks = args.batch_size * (args.num_train_iterations - 1)\n",
    "        print(\n",
    "            f'Training on {num_training_tasks} tasks with composition: '\n",
    "            f'num_way={args.num_way}, '\n",
    "            f'num_support={args.num_support}, '\n",
    "            f'num_query={args.num_query}'\n",
    "        )\n",
    "        dataloader_train = get_omniglot_dataloader(\n",
    "            'train', args.batch_size, args.num_way, args.num_support, args.num_query, num_training_tasks\n",
    "        )\n",
    "        dataloader_val = get_omniglot_dataloader(\n",
    "            'val', args.batch_size, args.num_way, args.num_support, args.num_query, args.batch_size * 4\n",
    "        )\n",
    "        maml.train(\n",
    "            dataloader_train, dataloader_val,\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            f'Testing on tasks with composition '\n",
    "            f'num_way={args.num_way}, '\n",
    "            f'num_support={args.num_support}, '\n",
    "            f'num_query={args.num_query}'\n",
    "        )\n",
    "        dataloader_test = get_omniglot_dataloader(\n",
    "            'test',\n",
    "            1,\n",
    "            args.num_way,\n",
    "            args.num_support,\n",
    "            args.num_query,\n",
    "            NUM_TEST_TASKS\n",
    "        )\n",
    "        maml.test(dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26544014-bc28-402b-90aa-7a18a74737d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(log_dir=None, num_way=5, num_support=1, num_query=15, num_inner_steps=1, inner_lr=0.4, learn_inner_lrs=False, outer_lr=0.001, batch_size=16, num_train_iterations=150, test=False, cache=False, device='cpu')\n",
      "Training on 2384 tasks with composition: num_way=5, num_support=1, num_query=15\n",
      "Starting training at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Spencer\\AppData\\Local\\Temp\\ipykernel_10032\\831245959.py:3: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning dissapear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  x = imageio.imread(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: loss: 1.585, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.363, post-adaptation query accuracy: 0.287\n",
      "Validation: loss: 1.554, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.422, post-adaptation query accuracy: 0.331\n",
      "Iteration 10: loss: 1.477, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.588, post-adaptation query accuracy: 0.435\n",
      "Iteration 20: loss: 1.439, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.588, post-adaptation query accuracy: 0.467\n",
      "Iteration 30: loss: 1.383, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.725, post-adaptation query accuracy: 0.512\n",
      "Iteration 40: loss: 1.322, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.688, post-adaptation query accuracy: 0.552\n",
      "Iteration 50: loss: 1.306, pre-adaptation support accuracy: 0.213, post-adaptation support accuracy: 0.700, post-adaptation query accuracy: 0.547\n",
      "Validation: loss: 1.290, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.747, post-adaptation query accuracy: 0.551\n",
      "Iteration 60: loss: 1.305, pre-adaptation support accuracy: 0.213, post-adaptation support accuracy: 0.675, post-adaptation query accuracy: 0.556\n",
      "Iteration 70: loss: 1.240, pre-adaptation support accuracy: 0.188, post-adaptation support accuracy: 0.775, post-adaptation query accuracy: 0.568\n",
      "Iteration 80: loss: 1.223, pre-adaptation support accuracy: 0.188, post-adaptation support accuracy: 0.825, post-adaptation query accuracy: 0.616\n",
      "Iteration 90: loss: 1.177, pre-adaptation support accuracy: 0.188, post-adaptation support accuracy: 0.850, post-adaptation query accuracy: 0.658\n",
      "Iteration 100: loss: 1.170, pre-adaptation support accuracy: 0.200, post-adaptation support accuracy: 0.838, post-adaptation query accuracy: 0.632\n",
      "Validation: loss: 1.172, pre-adaptation support accuracy: 0.191, post-adaptation support accuracy: 0.841, post-adaptation query accuracy: 0.627\n",
      "Iteration 110: loss: 1.141, pre-adaptation support accuracy: 0.188, post-adaptation support accuracy: 0.875, post-adaptation query accuracy: 0.614\n",
      "Iteration 120: loss: 1.140, pre-adaptation support accuracy: 0.238, post-adaptation support accuracy: 0.913, post-adaptation query accuracy: 0.669\n",
      "Iteration 130: loss: 1.133, pre-adaptation support accuracy: 0.175, post-adaptation support accuracy: 0.888, post-adaptation query accuracy: 0.673\n",
      "Iteration 140: loss: 1.085, pre-adaptation support accuracy: 0.225, post-adaptation support accuracy: 0.925, post-adaptation query accuracy: 0.661\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser('Train a MAML!')\n",
    "    parser.add_argument('--log_dir', type=str, default=None,\n",
    "                        help='directory to save to or load from')\n",
    "    parser.add_argument('--num_way', type=int, default=5,\n",
    "                        help='number of classes in a task')\n",
    "    parser.add_argument('--num_support', type=int, default=1,\n",
    "                        help='number of support examples per class in a task')\n",
    "    parser.add_argument('--num_query', type=int, default=15,\n",
    "                        help='number of query examples per class in a task')\n",
    "    parser.add_argument('--num_inner_steps', type=int, default=1,\n",
    "                        help='number of inner-loop updates')\n",
    "    parser.add_argument('--inner_lr', type=float, default=0.4,\n",
    "                        help='inner-loop learning rate initialization')\n",
    "    parser.add_argument('--learn_inner_lrs', default=False, action='store_true',\n",
    "                        help='whether to optimize inner-loop learning rates')\n",
    "    parser.add_argument('--outer_lr', type=float, default=0.001,\n",
    "                        help='outer-loop learning rate')\n",
    "    parser.add_argument('--batch_size', type=int, default=16,\n",
    "                        help='number of tasks per outer-loop update')\n",
    "    parser.add_argument('--num_train_iterations', type=int, default=150,\n",
    "                        help='number of outer-loop updates to train for')\n",
    "    parser.add_argument('--test', default=False, action='store_true',\n",
    "                        help='train or test')\n",
    "    parser.add_argument('--cache', action='store_true')\n",
    "    parser.add_argument('--device', type=str, default='cpu')\n",
    "\n",
    "    args, unknown = parser.parse_known_args()\n",
    "\n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mann",
   "language": "python",
   "name": "mann"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
